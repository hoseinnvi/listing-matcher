{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ac5941-a935-497f-932c-c178f6f6a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import usaddress\n",
    "import re\n",
    "import logging\n",
    "\n",
    "# Configure logger once\n",
    "logger = logging.getLogger(\"address_parser\")\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.FileHandler(\"parse_failures.log\")\n",
    "logger.addHandler(handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1863959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import usaddress\n",
    "import re\n",
    "import logging\n",
    "\n",
    "# --- Logging setup with handler guard ---\n",
    "logger = logging.getLogger(\"address_parser\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    handler = logging.FileHandler(\"parse_failures.log\")\n",
    "    formatter = logging.Formatter(\"%(asctime)s %(levelname)s %(message)s\")\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# --- Abbreviation normalization ---\n",
    "ABBREVIATIONS = {\n",
    "    \"st\": \"street\", \"ave\": \"avenue\", \"rd\": \"road\", \"blvd\": \"boulevard\",\n",
    "    \"dr\": \"drive\", \"n\": \"north\", \"s\": \"south\", \"e\": \"east\", \"w\": \"west\"\n",
    "}\n",
    "\n",
    "def normalize_string(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[.,#]\", \"\", s)\n",
    "    tokens = s.split()\n",
    "    tokens = [ABBREVIATIONS.get(tok, tok) for tok in tokens]\n",
    "    return \" \".join(tokens).strip()\n",
    "\n",
    "# --- Unit splitting before parsing ---\n",
    "def split_unit(addr: str):\n",
    "    parts = re.split(r'\\s*-\\s*|\\s+#\\s*', addr, maxsplit=1)\n",
    "    street = parts[0]\n",
    "    unit = parts[1] if len(parts) > 1 else ''\n",
    "    return street.strip(), unit.strip()\n",
    "\n",
    "def enhanced_parse_full(addr: str):\n",
    "    raw_street, unit_part = split_unit(addr)\n",
    "    try:\n",
    "        parsed, _ = usaddress.tag(raw_street)\n",
    "    except usaddress.RepeatedLabelError as e:\n",
    "        logger.info(f\"RepeatedLabelError for '{addr}': {e}\")\n",
    "        return {}, unit_part\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Parse failure for '{addr}': {e}\")\n",
    "        return {}, unit_part\n",
    "    return parsed, unit_part\n",
    "\n",
    "# --- Load data ---\n",
    "prop = pd.read_csv(\"properties-out.csv\")\n",
    "listing = pd.read_csv(\"listings-out.csv\")\n",
    "\n",
    "# Normalize property types\n",
    "TYPE_MAP = {\n",
    "    \"Apartment Building\": \"Apartment\",\n",
    "    \"Apartment Floor Plan\": \"Apartment\"\n",
    "}\n",
    "prop[\"type_norm\"] = prop[\"type\"].map(TYPE_MAP).fillna(prop[\"type\"])\n",
    "\n",
    "# --- Process properties ---\n",
    "parsed_results = prop[\"street_address\"].fillna(\"\").apply(enhanced_parse_full)\n",
    "prop[\"parsed\"], prop[\"unit_part\"] = zip(*parsed_results)\n",
    "\n",
    "prop[\"street_part\"] = prop[\"parsed\"].apply(lambda d: \" \".join([\n",
    "    d.get(\"AddressNumber\", \"\"),\n",
    "    d.get(\"StreetName\", \"\"),\n",
    "    d.get(\"StreetNamePostType\", \"\")\n",
    "]).strip())\n",
    "\n",
    "prop[\"full_address\"] = (\n",
    "    prop[\"street_part\"] + \" \" +\n",
    "    prop[\"city\"].fillna(\"\") + \" \" +\n",
    "    prop[\"state\"].fillna(\"\") + \" \" +\n",
    "    prop[\"zipcode\"].astype(str)\n",
    ").str.strip()\n",
    "\n",
    "prop[\"token_set\"] = prop[\"full_address\"].str.lower().str.split().apply(lambda x: \" \".join(sorted(set(x))))\n",
    "\n",
    "# --- Final property frame for DB ---\n",
    "prop_clean = prop[[\n",
    "    \"property_id\", \"team_id\", \"street_part\", \"unit_part\",\n",
    "    \"city\", \"state\", \"zipcode\", \"full_address\",\n",
    "    \"token_set\", \"type_norm\"\n",
    "]]\n",
    "prop_clean.to_csv(\"properties_cleaned.csv\", index=False)\n",
    "\n",
    "# --- Process listings ---\n",
    "parsed_results = listing[\"name\"].fillna(\"\").apply(enhanced_parse_full)\n",
    "listing[\"parsed\"], listing[\"unit_part\"] = zip(*parsed_results)\n",
    "\n",
    "listing[\"street_part\"] = listing[\"parsed\"].apply(lambda d: \" \".join([\n",
    "    d.get(\"AddressNumber\", \"\"),\n",
    "    d.get(\"StreetName\", \"\"),\n",
    "    d.get(\"StreetNamePostType\", \"\")\n",
    "]).strip())\n",
    "\n",
    "listing[\"city\"] = listing[\"parsed\"].apply(lambda d: d.get(\"PlaceName\", \"\"))\n",
    "listing[\"state\"] = listing[\"parsed\"].apply(lambda d: d.get(\"StateName\", \"\"))\n",
    "listing[\"zipcode\"] = listing[\"parsed\"].apply(lambda d: d.get(\"ZipCode\", \"\"))\n",
    "\n",
    "listing[\"full_address\"] = (\n",
    "    listing[\"street_part\"] + \" \" +\n",
    "    listing[\"city\"] + \" \" +\n",
    "    listing[\"state\"] + \" \" +\n",
    "    listing[\"unit_part\"]\n",
    ").str.strip()\n",
    "\n",
    "listing[\"token_set\"] = listing[\"full_address\"].str.lower().str.split().apply(lambda x: \" \".join(sorted(set(x))))\n",
    "\n",
    "# --- Final listing frame for DB ---\n",
    "clean_listing = listing[[\n",
    "    \"listing_id\", \"property_id\", \"team_id\", \"street_part\", \"unit_part\",\n",
    "    \"city\", \"state\", \"zipcode\", \"full_address\", \"token_set\"\n",
    "]]\n",
    "clean_listing.to_csv(\"listings_clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
